{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.2 \n",
    "\n",
    "Tested SimpleNN on MNIST from torce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Simple Neural Network & Log_Softmax \n",
    "\n",
    "### Optimzer using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x) \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = SNN()\n",
    "\n",
    "\n",
    "learning_rate = 0.01 \n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.3\n",
    "Do write a lot of code snippets to make sure that things are correct.\n",
    "\n",
    "Leave them here so that we could see that you have tried\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "\n",
    "# Format of path: root/train/label_name/image-id.jpeg\n",
    "# Format of path: root/test/label_name/image-id.jpeg\n",
    "\n",
    "\n",
    "test_directory = \"MNIST Dataset JPG format\\\\MNIST - JPG - testing\"\n",
    "training_directory = \"MNIST Dataset JPG format\\\\MNIST - JPG - training\"\n",
    "\n",
    "\n",
    "full_test_directory = os.path.join(os.getcwd(), test_directory)\n",
    "\n",
    "full_train_directory = os.path.join(os.getcwd(), training_directory)\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(full_train_directory) if f.is_dir()]\n",
    "\n",
    "image_paths = [] # Stores the image paths \n",
    "\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    image_pattern = os.path.join(subfolder, '*.jpg')  # Pattern Matching to get all the JPEG\n",
    "    image_paths.extend(glob.glob(image_pattern)) # Glob to get all images\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset): # Since I want to use DataLoader to load batches of images \n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) # Number of data points \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations\n",
    "    \n",
    "        # No need to apply ToTensor again, just flatten if required\n",
    "        image = image.view(-1)  # Flatten the image\n",
    "    \n",
    "        label = int(os.path.basename(os.path.dirname(img_path)))  # Extract label\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_cnn_model.to(torch.device('cpu'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert to grayscale\n",
    "    transforms.Resize((28, 28)),  # Resize \n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
    "])\n",
    "\n",
    "custom_dataset = CustomDataset(image_paths, transform)\n",
    "batch_size = 64\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "losses_over_time = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(custom_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(custom_dataloader)\n",
    "\n",
    "    losses_over_time.append(average_loss) # Append the average loss to the list\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss}')\n",
    "\n",
    "plt.plot(losses_over_time)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of the Model with the Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [f.path for f in os.scandir(full_test_directory) if f.is_dir()]\n",
    "image_paths2 = [] # Stores the image paths \n",
    "\n",
    "for subfolder in subfolders:\n",
    "    image_pattern = os.path.join(subfolder, '*.jpg')  # Pattern Matching to get all the JPEG\n",
    "    image_paths2.extend(glob.glob(image_pattern)) # Glob to get all images \n",
    "\n",
    "# Create the CustomDataset for testing\n",
    "custom_dataset = CustomDataset(image_paths2, transform)\n",
    "batch_size = 64\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test the model and visualize predictions\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of test data\n",
    "dataiter = iter(custom_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Predict labels\n",
    "net.eval()  # set to evaluation mode\n",
    "with torch.no_grad():  # disable gradients (takes memory)\n",
    "    outputs = simple_cnn_model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show number and prediction side by side\n",
    "fig = plt.figure(figsize=(25, 4))  # create a figure with a larger size\n",
    "for idx in range(min(64, batch_size)):  # loop over all images in the batch\n",
    "    ax = fig.add_subplot(4, 16, idx + 1, xticks=[], yticks=[])  # create a subplot for each image\n",
    "    ax.imshow(images[idx].squeeze(), cmap='gray')  # show the image in grayscale\n",
    "    ax.text(\n",
    "        0.5, -0.5, f'{labels[idx].item()} ({predicted[idx].item()})',\n",
    "        ha='center',\n",
    "        color='green' if labels[idx] == predicted[idx] else 'red'\n",
    "    )  # add text annotation with the number and prediction, using green color for correct predictions and red color for wrong predictions\n",
    "plt.show()  # show the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to .pth\n",
    "torch.save(net.state_dict(), 'deep_snn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "Follow this link https://pytorch.org/tutorials/beginner/basics/data_tutorial.html \n",
    "- Define the Dataset Class with 3 functions to get item\n",
    "- Use the Dataloader in the training loop\n",
    "- Iterate through the dataloader in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
